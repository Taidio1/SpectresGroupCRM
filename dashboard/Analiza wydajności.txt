Problemy z Przeładowywaniem Komponentów
Oddzielne montowanie komponentów przy każdej nawigacji: Obecna architektura powoduje, że kluczowe komponenty są montowane od nowa przy każdym wejściu na daną podstronę. Przykładowo każda strona (np. Klienci, Admin, Dashboard) renderuje wspólny layout (ProtectedLayout z bocznym menu i nagłówkiem) niezależnie. Kod wskazuje, że każda strona owinięta jest w ProtectedLayout z własnym stanem, zamiast korzystać z jednego, utrzymywanego w stanie globalnym layoutu
GitHub
GitHub
. W efekcie za każdym powrotem do strony komponenty takie jak Sidebar czy Header są ponownie montowane, co może generować niepotrzebny narzut. Rozwiązaniem może być wykorzystanie mechanizmu layoutów Next.js (App Router) – utworzenie wspólnego layoutu dla chronionych podstron aplikacji, tak by Sidebar, Header i inne stałe elementy UI nie były demontowane między podstronami, lecz pozostawały w pamięci. Taka refaktoryzacja ograniczy koszt ponownego renderowania tych samych elementów UI przy nawigacji wewnątrz aplikacji. Wymuszone ponowne renderowanie danych przy montowaniu: W komponentach kluczowych brakuje mechanizmu pamiętania załadowanych wcześniej danych, przez co przy każdym wejściu na stronę następuje ponowne pobranie i render danych. Na przykład, komponent ClientsTable przy każdym montowaniu (wejściu na stronę Klienci) wywołuje efekt useEffect zależny od użytkownika i inicjuje pełne załadowanie listy klientów z bazy
GitHub
. Podobnie główny Dashboard użytkownika przy każdym załadowaniu wykonuje cztery oddzielne zapytania (klienci, harmonogram dnia, top pracownicy, trendy sprzedaży) – wszystkie wyzwalane w useEffect po wykryciu zalogowanego użytkownika
GitHub
. Powoduje to wielokrotne przetwarzanie i re-fetching tych samych danych przy każdej wizycie użytkownika na danej podstronie, zamiast wykorzystać już pobrane informacje.
Nadmierne Pobieranie Danych
Powielone pobieranie list klientów: Obecny kod kilkukrotnie i niezależnie pobiera pełną listę klientów z bazy Supabase w różnych miejscach.
Na stronie Klienci funkcja loadClientsFromDatabase zawsze pobiera wszystkich klientów (wywołanie clientsApi.getClients) i zapisuje ich lokalnie w stanie komponentu
GitHub
.
Na panelu administratora (AdminPanel) w funkcji loadSystemStats ponownie pobierana jest pełna lista klientów tylko w celu obliczenia statystyk (liczby rekordów itp.)
GitHub
.
Dodatkowo, Dashboard użytkownika również pobiera pełną listę klientów (przez clientsApi.getClients), by następnie filtrować ją względem uprawnień użytkownika
GitHub
.
Te trzy niezależne zapytania powodują, że ta sama tabela clients jest odczytywana wielokrotnie z bazy przy przechodzeniu między widokami (Dashboard → Klienci → Admin). Jest to nieefektywne zarówno po stronie front-end (czas parsowania danych, renderowanie) jak i back-end (obciążenie bazy). Powielone pobieranie list użytkowników: Analogiczny problem dotyczy listy użytkowników systemu. Na stronie Klienci po załadowaniu klientów następuje pobranie wszystkich użytkowników (authApi.getAllUsersForDisplay) w celu przypisania nazwiska właściciela do klienta i wypełnienia filtra właścicieli
GitHub
. Z kolei panel administratora w loadSystemStats również pobiera pełną listę użytkowników (authApi.getAllUsersForDisplay) przy każdym otwarciu sekcji admina
GitHub
. Brak współdzielenia tych danych skutkuje dublowaniem zapytań – np. lista pracowników jest ładowana osobno w widoku klientów i osobno w widoku admin, mimo że w danej sesji aplikacji raczej się nie zmieni. Brak wykorzystania globalnego store do cache danych: Wprawdzie aplikacja posiada zaimplementowany globalny store Zustand (useStore) z polami clients i akcjami setClients itp.
GitHub
GitHub
, jednak w praktyce komponenty nie korzystają z tego store do przechowywania załadowanych danych. Zamiast tego posługują się lokalnym stanem (useState) w każdym widoku i zawsze inicjują go od zera. Jest to stracona szansa – istniejąca infrastruktura globalnego stanu mogłaby posłużyć do cache’owania listy klientów czy użytkowników po pierwszym pobraniu. Aktualnie jednak stan globalny pomija te informacje (celowo nie zapisuje klientów w localStorage
GitHub
, co jest zrozumiałe ze względów pamięciowych i RLS, ale nic nie stoi na przeszkodzie, by przechować je w pamięci w trakcie działania aplikacji). Zalecenie: Należy rozważyć wprowadzenie mechanizmu cache’owania danych na front-endzie. Przykładowo:
Po pobraniu listy klientów w widoku Klienci można zapisać ją w globalnym store (lub kontekście) i udostępnić innym komponentom. Inne części aplikacji (np. Dashboard, AdminPanel) mogłyby najpierw sprawdzić, czy globalny store zawiera już dane klientów – jeśli tak, użyć ich zamiast inicjować kolejne zapytanie. Taki cache powinien być oczywiście odświeżany przy operacjach modyfikujących (dodanie/edycja/usunięcie klienta), ale to i tak zredukuje liczbę pełnych refetchów.
Alternatywnie, można zastosować biblioteki typu React Query / TanStack Query lub SWR, które automatycznie cachują wyniki zapytań i umożliwiają współdzielenie ich między komponentami. W projekcie znajduje się dokumentacja sugerująca takie podejście – np. wykorzystanie useQuery z kluczem zapytania by cache’ować metryki dashboardu czy listy klientów
GitHub
GitHub
. Za pomocą React Query widok Klienci mógłby odpytywać clientsApi.getClientsPaginated z opcją staleTime i keepPreviousData, dzięki czemu dane klientów pozostaną w pamięci pomiędzy zmianami strony, a odświeżanie będzie następować tylko przy niezbędnych okazjach (lub w tle). Zacytowany fragment kodu pokazuje przykład implementacji paginacji z cachingiem: zapytania o klientów identyfikowane kluczem strony i filtrów, z włączonym cache na 30 sekund
GitHub
. Takie podejście zapobiegnie wielokrotnemu pobieraniu tych samych danych w krótkim czasie.
Możliwości Optymalizacji w Kodzie
Memoizacja i Ograniczenie Niepotrzebnych Renderów
Memoizacja wyników filtracji i obliczeń: Komponent ClientsTable wykonuje filtrowanie i sortowanie listy klientów za każdym razem, gdy zmieni się którykolwiek z parametrów filtrowania lub lista danych
GitHub
GitHub
. Obecnie jest to realizowane w useEffect, który przy każdej zmianie stanu (np. wpisaniu frazy wyszukiwania, zmianie filtra statusu) aktualizuje stan filteredClients i paginatedClients. Rozwiązanie to działa poprawnie, ale można rozważyć wykorzystanie useMemo do obliczania przefiltrowanej i posortowanej listy – tak aby uniknąć przeliczania filtrów przy każdym renderze, jeśli dane wejściowe się nie zmieniły. Memoizacja listy klientów po filtracji (np. zależnej od clients, searchQuery, itd.) może odciążyć render, zwłaszcza przy większych listach. Podobnie, kosztowne obliczenia jak wyliczanie statystyk statusów na dashboardzie czy sortowanie top pracowników można opakować w useMemo – tak by komponent nie przeliczał ich ponownie bez potrzeby. Choć aktualnie stosowany debouncing wyszukiwania już zapobiega części niepotrzebnych operacji
GitHub
, to dalsza optymalizacja przez memoizację może zmniejszyć częstotliwość renderów i obciążeń CPU przy intensywnym korzystaniu z filtrów. Unikanie niepotrzebnych aktualizacji kontekstu: Warto upewnić się, że globalny kontekst (np. kontekst autoryzacji czy języka) nie powoduje nadmiernych re-renderów dzieci. Obecny LanguageProvider i AuthProvider są umieszczone globalnie, co jest prawidłowe. Należy jednak sprawdzić, czy np. zmiana drobnego stanu w kontekście (niezwiązanego z danym komponentem) nie powoduje przeładowania dużych fragmentów UI. Jeżeli tak, można rozważyć rozbicie kontekstu na mniejsze (np. osobny kontekst dla danych użytkownika, osobny dla preferencji językowych), bądź wykorzystanie selektorów Zustand (które już są – np. useAuth, useClients) aby komponenty subskrybowały tylko potrzebne fragmenty stanu. Dzięki temu np. zmiana bieżącej strony (currentPage) w store nie będzie powodowała, że wszystkie komponenty korzystające z useAuth się prze-renderują. React.memo dla ciężkich podkomponentów: Jeśli w tabeli klientów wydzielimy podkomponenty (np. wiersz tabeli jako osobny komponent ClientRow), można owinąć je w React.memo. Wówczas zmiana stanu niezwiązana z danym wierszem (np. zmiana zaznaczenia innego wiersza, lub otwarcie okna modalnego) nie spowoduje przerysowania wszystkich wierszy tabeli, tylko najwyżej tego jednego. W aktualnej implementacji tabela jest renderowana całościowo w mapie, co oznacza że każda zmiana listy filteredClients powoduje render całej listy wierszy od nowa. Przy 25 elementach na stronę nie jest to dużym problemem, ale przy większych stronach lub braku paginacji może to wpływać na płynność. Zastosowanie memo() lub jeszcze lepiej wirtualizacji (omówionej poniżej) rozwiąże ten problem przy rosnącej skali danych.
Cache'owanie i Ponowne Wykorzystanie Danych
Jak wspomniano wyżej, zdecydowanie zaleca się zaimplementowanie mechanizmów cache’owania wyników zapytań. Kilka konkretnych propozycji:
React Query / SWR: Wprowadzenie biblioteki do zarządzania stanem asynchronicznym odciąży programistę od ręcznego budowania logiki cache. React Query może utrzymywać dane np. klientów pod kluczem zapytania i automatycznie odświeżać je w interwałach lub na żądanie. Co ważne, umożliwi to współdzielenie pobranych danych między różnymi komponentami. Dokumentacja projektu sugeruje już użycie React Query w przyszłości – np. dla metryk dashboardu z cache 2 minuty czy dla paginacji klientów
GitHub
GitHub
. Zaimplementowanie tych sugestii znacząco poprawi wydajność: dane raz pobrane będą serwowane z pamięci przy kolejnych renderach komponentu, a zapytania do bazy zostaną zredukowane do minimum.
Cache przeglądarki / localStorage: Dla mniej wrażliwych danych lub opcji konfiguracyjnych można wykorzystać localStorage lub IndexedDB. Aplikacja korzysta z zustand/persist aby zapisywać wybrane fragmenty stanu (user, isAuthenticated itp.) w localStorage
GitHub
. Nie zalecamy przechowywania całych list klientów w localStorage (co zresztą zostało świadomie wykluczone), ale pewne wolnozmienne dane (np. lista dostępnych lokalizacji, stałe słowniki) mogłyby być cachowane między sesjami użytkownika. To ograniczy czas oczekiwania przy pierwszym wejściu na stronę wymagającą tych danych.
Wykorzystanie mechanizmów przeglądarki: Jeśli pewne zapytania HTTP są powtarzalne i mają odpowiednie nagłówki cache-control, przeglądarka mogłaby cache’ować ich wyniki. Warto sprawdzić, czy zapytania do Supabase (np. pobranie awatara, statycznych plików czy może nawet zapytań) mogą korzystać z takiego cache. Alternatywnie, rozważenie warstwy Service Workera do cache’owania offline (jeśli kiedyś taka potrzeba wystąpi) – to jednak bardziej zaawansowany temat poza zakresem podstawowej optymalizacji.
Server-Side Rendering (SSR) i Statyczne Generowanie (SSG)
Renderowanie po stronie serwera: Rozważenie SSR dla niektórych stron mogłoby poprawić odczuwalną wydajność aplikacji. Obecnie wszystkie dane pobierane są po stronie klienta w useEffect (co widać po użyciu "use client" na początku większości plików Page). To oznacza, że użytkownik po nawigacji widzi najpierw spinnery/szkielety, a dopiero potem właściwe dane. Dzięki SSR możemy przygotować część danych wcześniej i dostarczyć użytkownikowi gotowy HTML. Na przykład strona Klienci mogłaby korzystać z funkcji server-side (np. w Next.js App Router poprzez fetch w komponencie bez use client, bądź w Pages Router poprzez getServerSideProps) aby pobrać wstępnie listę klientów (lub jej fragment) jeszcze przed renderem. To samo dotyczy panelu admina – statystyki systemowe (liczby użytkowników, klientów) mogłyby być zwracane z SSR, dzięki czemu panel pokaże je natychmiast bez oczekiwania na efekt useEffect. Wyzwania SSR w kontekście Supabase: Należy zauważyć, że implementacja SSR musi uwzględniać autoryzację. Supabase udostępnia mechanizmy, które pozwalają na weryfikację sesji użytkownika po stronie serwera (np. poprzez token w cookies lub przekazanie Access Tokena). Trzeba by tak skonfigurować SSR, by zapytania na serwerze respektowały RLS i uprawnienia użytkownika – np. użyć Supabase Admin API ostrożnie lub lepiej, skorzystać z funkcji middleware Next.js do przekierowania niezalogowanych. Mimo to, korzyści mogą być znaczące: SSR skraca czas do pełnego załadowania widoku i redukuje odczucie „migotania” zawartości (layout vs dane). Statyczne generowanie (SSG): W przypadku tej aplikacji SSG ma ograniczone zastosowanie, ponieważ większość stron zawiera dane dynamiczne zależne od zalogowanego użytkownika lub często zmieniających się danych (klienci, logi, statystyki). SSG można jednak zastosować dla stron, które są wspólne dla wszystkich użytkowników i rzadko się zmieniają. Przykładowo, jeżeli istniałaby strona pomocy, dokumentacji lub inne stałe treści – można by je generować statycznie, poprawiając szybkość ładowania. Dla samego panelu CRM można ewentualnie pre-generować szkielet strony z layoutem. Next.js App Router umożliwia deklarację segmentów jako statyczne lub dynamiczne. Można by wygenerować statycznie ogólny układ (Sidebar, Header z placeholderami) i użyć Suspense do doczytania danych po stronie klienta. To podejście hybrydowe (SSG + CSR) zapewni natychmiastowy widok struktury strony i późniejsze doładowanie treści. Podsumowując, SSR/SSG to opcje wymagające większych zmian architektury, ale mogą znacząco poprawić pierwszy czas renderu i wrażenia użytkownika przy wejściu na aplikację. Wdrożenie SSR należy rozważyć przede wszystkim dla tych podstron, gdzie jednorazowo pobierana jest duża ilość danych (lista klientów, raporty) – aby odciążyć przeglądarkę i łącze użytkownika.
Lazy Loading i React Suspense
Lazy loading komponentów: Aplikacja już częściowo wykorzystuje leniwe ładowanie – np. komponent ClientDetailsPopup (szczegóły klienta w modalu) jest ładowany dynamicznie dopiero w momencie potrzeby (React.lazy w LazyComponents.tsx i użycie LazyClientDetailsPopupWrapper)
GitHub
GitHub
. To znakomita praktyka, którą warto rozszerzyć na inne fragmenty. Zidentyfikowano kilka dużych komponentów, które obecnie są ładowane od razu, mimo że użytkownik nie zawsze z nich korzysta:
PerformanceDashboard na panelu admina – jest to ciężki komponent administracyjny z dodatkowymi zapytaniami do API, a jednak w AdminPanel został zaimportowany i renderowany bezpośrednio w zakładce Performance
GitHub
. Skutkuje to tym, że nawet jeśli administrator nie przełączy się na zakładkę "Performance", kod i dane tego panelu są ładowane w tle. W pliku LazyComponents.tsx widać przygotowaną lazy-wersję (LazyPerformanceDashboard) wraz ze skeletonem
GitHub
GitHub
, lecz aktualnie AdminPanel nie korzysta z niej – komponent jest montowany natychmiast. Rekomendujemy zmienić implementację zakładki wydajności tak, by używała LazyPerformanceDashboardWrapper. Dzięki temu kod oraz zapytania w PerformanceDashboard zostaną wykonane dopiero przy faktycznym otwarciu tej zakładki przez użytkownika. To samo dotyczy innych możliwych miejsc:
Raporty (GeneralReports, Reports) – komponenty raportów również mogą być duże (wykresy, tabele). W LazyComponents.tsx zdefiniowano LazyGeneralReports i LazyReports
GitHub
, jednak strony raportów (app/reports/general itp.) nadal importują komponenty raportów w sposób stały
GitHub
. Warto zastosować dynamiczny import z Suspense dla podstron raportów, zwłaszcza jeśli generują one złożone wykresy lub tabele. W kontekście Next.js można użyć funkcji next/dynamic do leniwego ładowania tych komponentów.
Wykorzystanie React Suspense: Leniwe ładowanie komponentów powinno być połączone z Suspense, aby pokazać użytkownikowi placeholder podczas dogrywania modułu. W projekcie w kilku miejscach zastosowano już Suspense – np. w komponencie Dashboard otoczono całą główną siatkę kart w <Suspense> z prostym loaderem
GitHub
. Niemniej jednak, ponieważ wewnątrz nie było faktycznie asynchronicznych komponentów, Suspense tam pełni rolę przygotowania pod future use (być może planowano uczynić niektóre sekcje Dashboard lazy). Zalecamy:
Stosować Suspense dla sekcji ładowanych warunkowo – np. sekcja statystyk w dashboardzie menedżera (Top pracownicy, trendy) mogłaby być jednym lazy-komponentem opakowanym w Suspense, co pozwoliłoby wyświetlić np. skeleton wykresów zanim dane się załadują.
Suspense dla danych z fetch – rozważenie użycia funkcji React 18, które pozwalają na zawieszenie renderu do czasu spełnienia obietnicy (Promise). Przykładowo, Next.js 13 w trybie React Server Components pozwala zwracać Promise z danych i automatycznie wstrzymywać render. W tradycyjnym CSR można skorzystać z bibliotek pomocniczych (lub poczekać na oficjalne React Suspense for data). Obecnie i tak stosujemy useEffect + własne spinnery, ale migracja np. na React Query mogłaby uprościć kod: zamiast ręcznie śledzić loading i warunki renderowania, można zdać się na to, że komponent poczeka (z pomocą Suspense) na useQuery. To jednak głębsza zmiana wymagająca dojrzałości biblioteki – na ten moment wystarczy konsekwentnie używać lazy + Suspense dla komponentów UI.
Podział kodu (code splitting): Dzięki lazy loadingowi i Suspense możemy podzielić aplikację na mniejsze kawałki ładowane na żądanie, co obniży zużycie pamięci i przyspieszy inicjalne ładowanie. Warto przeanalizować bundle aplikacji – jeśli jakieś moduły (np. biblioteka wykresów recharts, duże ikony lucide-react, czy obsługa CSV) nie są potrzebne od razu przy starcie aplikacji, należy je ładować leniwie. Przykładowo, kod do importu plików CSV w ClientsTable mógłby być wyodrębniony do osobnego, leniwie wczytywanego modułu, aktywowanego dopiero po kliknięciu „Importuj z CSV”. Obecnie wszystko jest w jednym pliku komponentu ClientsTable (ponad 3000 linii kodu), co oznacza, że użytkownik ładuje logikę wielu funkcji, z których może nigdy nie skorzystać w danej sesji (np. funkcje czyszczenia niepoprawnych owner_id, test połączenia bazy, itp. są zawsze wczytywane
GitHub
GitHub
). Wydzielenie tych funkcjonalności do modułów on-demand uczyni aplikację lżejszą przy pierwszym uruchomieniu.
Zmiany Strukturalne i Refaktoryzacja
Refaktoryzacja komponentów strony klientów: Komponent ClientsTable jest bardzo rozbudowany (zawiera obsługę tabeli, filtrowania, paginacji, modali dodawania/edycji, importu CSV, subskrypcji real-time, etc. w jednym pliku). To utrudnia utrzymanie i może wpływać na wydajność. Rozważmy podział go na mniejsze komponenty logiczne:
Komponent prezentacyjny Tabela (renderujący wiersze na podstawie propsów: listy klientów, stanu ładowania, itp.).
Komponent filtry + pasek narzędzi (wyszukiwarka, dropdowny filtrów, przyciski eksportu/importu).
Osobne komponenty dla modali: formularz dodawania/edycji klienta, popup szczegółów (już jest wydzielony), okno importu CSV. Te modale można ładować leniwie (Next.js dynamic import) – np. modal importu CSV zawierający ciężką logikę parsowania pliku może być wczytany dopiero po wybraniu pliku przez użytkownika.
Taki podział zapewni, że zmiana stanu w jednej części (np. zamknięcie modalu) nie powoduje re-renderu całej tabeli. Ułatwi też profilowanie wydajności – mniejsze komponenty łatwiej zoptymalizować osobno (np. React.memo jak wspomniano). Dodatkowo, testowanie i dalsza rozbudowa funkcjonalności staną się prostsze. Pagination i wirtualizacja list: Aktualna implementacja paginuje klientów po stronie frontendu – od razu pobiera wszystkich klientów i potem rozbija ich na strony w stanie komponentu
GitHub
. Dla małych baz jest to akceptowalne, lecz przy większej liczbie rekordów (setki tysięcy) będzie to nieefektywne (transfer i utrzymanie tak dużej tablicy w pamięci). Już teraz przewidziano mechanizm paginacji po stronie bazy (clientsApi.getClientsPaginated) zliczający total i pobierający tylko potrzebny zakres
GitHub
GitHub
 – warto go wykorzystać zamiast pobierać wszystko na raz. Idealnie, integracja z React Query pozwoliłaby stronicować z keepPreviousData (jak w sugestii dokumentacji) i wyświetlać np. skeleton podczas przełączania stron, zamiast blokować UI. Jeśli jednak często będziemy chcieli wyświetlać wszystkich klientów na raz (np. eksport, masowe operacje), zalecane jest wprowadzenie wirtualizacji listy. Biblioteki takie jak react-window umożliwiają renderowanie tylko widocznych elementów listy. Dokumentacja projektu również wspomina o virtual scroll dla dużych list
GitHub
. W praktyce oznacza to, że niezależnie od liczby klientów, w DOM będzie np. tylko 20-50 elementów naraz (co odpowiada widocznemu obszarowi), a reszta będzie renderowana na bieżąco przy przewijaniu. To drastycznie poprawi wydajność manipulacji listą w przeglądarce (mniej elementów DOM = płynniejsze scrollowanie, mniejsze zużycie pamięci). Virtualizacja powinna iść w parze z paginacją po stronie serwera przy ekstremalnie dużych zbiorach – możemy np. założyć, że wyświetlamy maksymalnie 1000 wyników naraz zwirtualizowanych, a powyżej tego użytkownik i tak zastosuje filtry albo inny mechanizm. Wykorzystanie procedur składowanych i materiałowanych widoków: Choć to nie bezpośrednio front-end, warto wspomnieć, że optymalizacja wydajności aplikacji to również zmniejszenie pracy, którą front-end musi wykonać. Wgląd w repozytorium sugeruje już użycie materialized views oraz procedur Postgresa (RPC Supabase) do przyspieszenia zapytań
GitHub
. Np. funkcja RPC get_dashboard_metrics agregująca różne statystyki mogłaby zastąpić kilka osobnych zapytań wykonywanych w Dashboard (obecnie 4 osobne fetch do Supabase). Gdy front-end otrzyma już zagregowane dane jednym wywołaniem, zyska podwójnie: mniejsza ilość danych do przesłania i tylko jedno miejsce do obsługi stanu ładowania zamiast czterech. Rekomendujemy przejrzeć obecne zapytania wykonywane w efektach i sprawdzić, czy można je połączyć lub przenieść do bazy danych (z zachowaniem RLS). W module reportsApi/dashboardApi już widoczne są pomysły w tym kierunku (np. zmaterializowane widoki dla miesięcznych statystyk pracowników, które front-end mógłby pobrać jednym selectem zamiast wielu joinów
GitHub
). Podsumowanie zmian: Powyższe rekomendacje – od cache’owania przez SSR po lazy loading – sprowadzają się do jednej myśli: uniknąć wykonywania dwa razy tej samej kosztownej operacji. Należy wdrożyć mechanizmy, dzięki którym:
Dane są pobierane raz i wykorzystywane wielokrotnie (cache globalny, React Query).
Komponent lub funkcja jest uruchamiana tylko wtedy, kiedy jest potrzebna (lazy loading, podział kodu).
Renderujemy tylko to, co użytkownik faktycznie widzi (pagination, virtual scroll, memoizacja).
Część pracy wykonujemy wcześniej lub gdzie indziej (SSR na serwerze, agregacja w bazie) aby odciążyć klienta.
Wdrożenie tych usprawnień w aplikacji SpectresGroupCRM powinno zauważalnie poprawić płynność działania interfejsu – zmniejszy czas oczekiwania na dane przy przełączaniu widoków, ograniczy „mruganie” spowodowane ponownymi renderami tych samych komponentów i zredukuje obciążenie przeglądarki przy pracy z dużymi listami danych. Każda z wymienionych zmian powinna być poparta testami porównawczymi (przed/po) dla krytycznych scenariuszy, aby upewnić się, że rzeczywiście przynoszą oczekiwany zysk wydajności. Przy odpowiedniej implementacji, system będzie reagował szybciej na działania użytkownika, wykorzystując mniej zasobów i skalując się lepiej wraz ze wzrostem liczby danych.